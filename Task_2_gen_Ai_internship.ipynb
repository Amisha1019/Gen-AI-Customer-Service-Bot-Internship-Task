{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4qZT1CyB92h0xa1uK9XLg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amisha1019/Gen-AI-Customer-Service-Bot-Internship-Task/blob/main/Task_2_gen_Ai_internship.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  !pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yCzWV-i6ptuR",
        "outputId": "c99be3bc-e228-4c8f-89c1-7a7ef18d2188"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.0.339 (from -r requirements.txt (line 1))\n",
            "  Downloading langchain-0.0.339-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting python-dotenv==1.0.0 (from -r requirements.txt (line 2))\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting streamlit==1.22.0 (from -r requirements.txt (line 3))\n",
            "  Downloading streamlit-1.22.0-py2.py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting tiktoken==0.4.0 (from -r requirements.txt (line 4))\n",
            "  Downloading tiktoken-0.4.0.tar.gz (25 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 0.55.2 Requires-Python <3.5\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement faiss-cpu==1.7.4 (from versions: 1.8.0, 1.8.0.post1, 1.9.0, 1.9.0.post1, 1.10.0, 1.11.0, 1.11.0.post1, 1.12.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for faiss-cpu==1.7.4\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  GOOGLE_API_KEY=\"your_api_key_here\""
      ],
      "metadata": {
        "id": "ZfAksggXp4Ua"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import io\n",
        "from typing import Optional\n",
        "from fastapi import FastAPI, File, UploadFile, Form\n",
        "from fastapi.responses import JSONResponse, StreamingResponse\n",
        "from pydantic import BaseModel\n",
        "from PIL import Image\n",
        "import httpx\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
        "PALM_BASE = os.getenv(\"PALM_API_BASE\", \"https://generativelanguage.googleapis.com/v1\")\n",
        "GEMINI_BASE = os.getenv(\"GEMINI_API_BASE\", \"https://api.generative.google/v1\")\n",
        "PROJECT_ID = os.getenv(\"PROJECT_ID\")\n",
        "\n",
        "\n",
        "app = FastAPI(title=\"Multimodal Chatbot — PaLM + Gemini\")"
      ],
      "metadata": {
        "id": "fiphSx0lqYPU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def google_headers():\n",
        "    return {\"Authorization\": f\"Bearer {API_KEY}\", \"Content-Type\": \"application/json\"}\n",
        "\n",
        "\n",
        "async def call_palm_text(prompt: str, max_tokens: int = 512):\n",
        "    # Example using PaLM text generation endpoint\n",
        "    url = f\"{PALM_BASE}/models/text-bison:generate\"\n",
        "    payload = {\n",
        "        \"prompt\": {\"text\": prompt},\n",
        "        \"temperature\": 0.7,\n",
        "        \"maxOutputTokens\": max_tokens\n",
        "    }\n",
        "    async with httpx.AsyncClient(timeout=30.0) as client:\n",
        "        r = await client.post(url, json=payload, headers=google_headers())\n",
        "        r.raise_for_status()\n",
        "        return r.json()\n",
        "\n",
        "\n",
        "async def call_gemini_image_generate(prompt: str, size: str = \"1024x1024\"):\n",
        "    # Example Gemini image generation endpoint -- placeholder shape\n",
        "    url = f\"{GEMINI_BASE}/images:generate\"\n",
        "    payload = {\"prompt\": prompt, \"size\": size, \"num_images\": 1}\n",
        "    async with httpx.AsyncClient(timeout=60.0) as client:\n",
        "        r = await client.post(url, json=payload, headers=google_headers())\n",
        "        r.raise_for_status()\n",
        "        return r.json()\n",
        "\n",
        "\n",
        "async def call_gemini_vision_analyze(image_bytes: bytes):\n",
        "    # Example of sending image bytes encoded as base64 to Gemini Vision/Multimodal endpoint\n",
        "    url = f\"{GEMINI_BASE}/vision:analyze\"\n",
        "    b64 = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
        "    payload = {\"image\": {\"content\": b64}, \"features\": [\"TEXT_DETECTION\", \"LABEL_DETECTION\", \"OBJECT_DETECTION\"]}\n",
        "    async with httpx.AsyncClient(timeout=30.0) as client:\n",
        "        r = await client.post(url, json=payload, headers=google_headers())\n",
        "        r.raise_for_status()\n",
        "        return r.json()"
      ],
      "metadata": {
        "id": "tC1fpxBBqqOQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextRequest(BaseModel):\n",
        "    prompt: str\n",
        "\n",
        "\n",
        "class ImageGenRequest(BaseModel):\n",
        "    prompt: str\n",
        "    size: Optional[str] = \"1024x1024\""
      ],
      "metadata": {
        "id": "pNHvNM9-q0iv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.post('/content/text_to_image_dataset.csv')\n",
        "async def generate_text(req: TextRequest):\n",
        "    \"\"\"Generate a text reply using PaLM\"\"\"\n",
        "    try:\n",
        "        resp = await call_palm_text(req.prompt)\n",
        "        # Response shape may vary — adapt to your API version\n",
        "        output_text = resp.get('candidates', [{}])[0].get('content') or resp.get('output') or str(resp)\n",
        "        return JSONResponse({\"text\": output_text, \"raw\": resp})\n",
        "    except httpx.HTTPError as e:\n",
        "        return JSONResponse(status_code=500, content={\"error\": str(e)})\n",
        "\n",
        "\n",
        "@app.post('/content/text_to_image_dataset.csv')\n",
        "async def generate_image(req: ImageGenRequest):\n",
        "    \"\"\"Generate an image using Gemini Image API and return base64.\n",
        "    In production you'd return a URL to the stored image.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        resp = await call_gemini_image_generate(req.prompt, req.size)\n",
        "        # adapt according to actual Gemini result shape. Many providers return base64 image(s).\n",
        "        images = []\n",
        "        # Try common shapes: 'images' -> list of {b64: '...'} or 'data' -> ...\n",
        "        if isinstance(resp, dict):\n",
        "            if 'images' in resp:\n",
        "                images = resp['images']\n",
        "            elif 'data' in resp and isinstance(resp['data'], list):\n",
        "                images = resp['data']\n",
        "            else:\n",
        "                images = [resp]\n",
        "        return JSONResponse({\"images\": images, \"raw\": resp})\n",
        "    except httpx.HTTPError as e:\n",
        "        return JSONResponse(status_code=500, content={\"error\": str(e)})\n",
        "\n",
        "\n",
        "@app.post('/vision/analyze')\n",
        "async def vision_analyze(file: UploadFile = File(...)):\n",
        "    \"\"\"Accept an uploaded image and return Gemini Vision analysis.\"\"\"\n",
        "    try:\n",
        "        body = await file.read()\n",
        "        resp = await call_gemini_vision_analyze(body)\n",
        "        return JSONResponse({\"analysis\": resp})\n",
        "    except httpx.HTTPError as e:\n",
        "        return JSONResponse(status_code=500, content={\"error\": str(e)})\n",
        "\n",
        "\n",
        "# Simple health endpoint\n",
        "@app.get('/health')\n",
        "async def health():\n",
        "    return {\"status\": \"ok\"}"
      ],
      "metadata": {
        "id": "LEm45DXpq_RB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import base64\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import json\n",
        "\n",
        "# ---- Configuration ----\n",
        "BACKEND_URL = \"https://upload.wikimedia.org/wikipedia/commons/e/e3/Tropical_Beach.jpg\"   # or your deployed FastAPI server\n",
        "\n",
        "# ------------------------\n",
        "def generate_text(prompt):\n",
        "    \"\"\"\n",
        "    Send text prompt to FastAPI backend -> returns generated text.\n",
        "    \"\"\"\n",
        "    url = f\"{BACKEND_URL}https://upload.wikimedia.org/wikipedia/commons/e/e3/Tropical_Beach.jpg\"\n",
        "    payload = {\"prompt\": prompt}\n",
        "    try:\n",
        "        response = requests.post(url, json=payload)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        print(\"Text Generation Successful!\")\n",
        "        return data.get(\"text\", \"\")\n",
        "    except Exception as e:\n",
        "        print(\"Error generating text:\", e)\n",
        "        return None\n",
        "\n",
        "\n",
        "def generate_image_from_prompt(prompt, size=\"1024x1024\"):\n",
        "    \"\"\"\n",
        "    Generate an image from text prompt using the /generate/image endpoint.\n",
        "    Saves and shows the image locally.\n",
        "    \"\"\"\n",
        "    url = f\"{BACKEND_URL}/content/text_to_image_dataset.csv\"\n",
        "    payload = {\"prompt\": prompt, \"size\": size}\n",
        "    try:\n",
        "        response = requests.post(url, json=payload)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        # Extract image\n",
        "        image_entry = None\n",
        "        if \"images\" in data and len(data[\"images\"]) > 0:\n",
        "            image_entry = data[\"images\"][0]\n",
        "\n",
        "        if not image_entry:\n",
        "            print(\"No image found in response.\")\n",
        "            return None\n",
        "\n",
        "        b64 = (\n",
        "            image_entry.get(\"b64\")\n",
        "            or image_entry.get(\"base64\")\n",
        "            or image_entry.get(\"data\")\n",
        "            or image_entry.get(\"content\")\n",
        "        )\n",
        "\n",
        "        if b64:\n",
        "            img_data = base64.b64decode(b64)\n",
        "            image = Image.open(BytesIO(img_data))\n",
        "            image.save(\"generated_image.png\")\n",
        "            image.show()\n",
        "            print(\"Image saved as generated_image.png\")\n",
        "            return \"generated_image.png\"\n",
        "        elif \"url\" in image_entry:\n",
        "            print(\"Image available at URL:\", image_entry[\"https://upload.wikimedia.org/wikipedia/commons/e/e3/Tropical_Beach.jpg\"])\n",
        "            return image_entry[\"https://upload.wikimedia.org/wikipedia/commons/e/e3/Tropical_Beach.jpg\"]\n",
        "        else:\n",
        "            print(\"Could not decode image data.\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error generating image:\", e)\n",
        "        return None\n",
        "\n",
        "\n",
        "def analyze_image(image_path):\n",
        "    \"\"\"\n",
        "    Upload an image to the backend for visual analysis.\n",
        "    \"\"\"\n",
        "    url = f\"{BACKEND_URL}/vision/analyze\"\n",
        "    try:\n",
        "        with open(image_path, \"rb\") as f:\n",
        "            files = {\"file\": \"/content/text_to_image_dataset.csv\"}\n",
        "            response = requests.post(url, files=files)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        print(\"Image analysis complete!\")\n",
        "        print(json.dumps(data.get(\"analysis\", {}), indent=2))\n",
        "        return data.get(\"analysis\", {})\n",
        "    except Exception as e:\n",
        "        print(\"Error analyzing image:\", e)\n",
        "        return None\n",
        "\n",
        "\n",
        "# ------------------------\n",
        "# Example Usage:\n",
        "if __name__ == \"__main__\":\n",
        "    # Generate text\n",
        "    text_prompt = \"Describe the beauty of space exploration.\"\n",
        "    text_output = generate_text(text_prompt)\n",
        "    print(\"/content/text_to_image_dataset.csv\", text_output)\n",
        "\n",
        "    # Generate an image\n",
        "    image_prompt = \"A futuristic city on Mars at sunset.\"\n",
        "    image_path = generate_image_from_prompt(image_prompt)\n",
        "\n",
        "    # Analyze an existing image (optional)\n",
        "    if image_path:\n",
        "        analyze_image(\"/content/text_to_image_dataset.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoFPi7O6uutp",
        "outputId": "c5447930-45d1-4aeb-dd24-aca829a444e2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error generating text: 405 Client Error: Method Not Allowed for url: https://upload.wikimedia.org/wikipedia/commons/e/e3/Tropical_Beach.jpghttps://upload.wikimedia.org/wikipedia/commons/e/e3/Tropical_Beach.jpg\n",
            "/content/text_to_image_dataset.csv None\n",
            "Error generating image: 405 Client Error: Method Not Allowed for url: https://upload.wikimedia.org/wikipedia/commons/e/e3/Tropical_Beach.jpg/content/text_to_image_dataset.csv\n"
          ]
        }
      ]
    }
  ]
}