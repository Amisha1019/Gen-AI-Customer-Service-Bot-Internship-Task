{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFH1xyBooY70FcKzQ3Dv/W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amisha1019/Gen-AI-Customer-Service-Bot-Internship-Task/blob/main/Task_6_of_Gen_AI_intenrship.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZyIEVNnfUAw",
        "outputId": "fdb29fbe-1a5c-4aef-b843-48868781208e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: streamlit_multilingual_chatbot.py: command not found\n",
            "/bin/bash: -c: line 1: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 1: `Multilingual Customer Service Chatbot (Streamlit single-file app)'\n"
          ]
        }
      ],
      "source": [
        "!streamlit_multilingual_chatbot.py\n",
        "\n",
        "!Multilingual Customer Service Chatbot (Streamlit single-file app)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit langdetect openai transformers sentence-transformers spacy faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFqwCVNqgk72",
        "outputId": "c9e33413-9948-46bc-87ea-56a438b0d1c3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.51.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/981.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m972.8/981.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.7)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from langdetect) (1.17.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.4.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.28.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (2.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Downloading streamlit-1.51.0-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m119.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m132.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=11ada049b6943d5b3dd0549ee18f05be78ba72bbed15d22c0e9487caddb188e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/67/88/e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect, faiss-cpu, pydeck, streamlit\n",
            "Successfully installed faiss-cpu-1.12.0 langdetect-1.0.9 pydeck-0.9.1 streamlit-1.51.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Snx83ZMzgr04",
        "outputId": "75a051d3-d380-4ebe-d870-c0c1335bbd53"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run streamlit_multilingual_chatbot.py --server.port 8501\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jWQbfKGg02W",
        "outputId": "e3905f65-2e78-4724-870e-5dc1b8eaec2a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usage: streamlit run [OPTIONS] [TARGET] [ARGS]...\n",
            "Try 'streamlit run --help' for help.\n",
            "\n",
            "Error: Invalid value: File does not exist: streamlit_multilingual_chatbot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Tuple, Dict, Any, List\n",
        "import streamlit as st\n"
      ],
      "metadata": {
        "id": "Dih6zWfig4Ny"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from langdetect import detect_langs, DetectorFactory\n",
        "    DetectorFactory.seed = 0\n",
        "except Exception:\n",
        "    st.warning(\"Please install langdetect: pip install langdetect\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "R8eWZlTXg-10"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HAS_OPENAI = False\n",
        "try:\n",
        "    import openai\n",
        "    HAS_OPENAI = True\n",
        "except Exception:\n",
        "    pass"
      ],
      "metadata": {
        "id": "LBUS895XhCbx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HAS_TRANSFORMERS = False\n",
        "try:\n",
        "    from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "    HAS_TRANSFORMERS = True\n",
        "except Exception:\n",
        "    pass"
      ],
      "metadata": {
        "id": "OQA7qBuphGVW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HAS_SENTENCE_TRANSFORMERS = False\n",
        "try:\n",
        "    from sentence_transformers import SentenceTransformer, util\n",
        "    HAS_SENTENCE_TRANSFORMERS = True\n",
        "except Exception:\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "ffHk79E6hOH1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HAS_SPACY = False\n",
        "try:\n",
        "    import spacy\n",
        "    HAS_SPACY = True\n",
        "except Exception:\n",
        "    pass"
      ],
      "metadata": {
        "id": "WUGgqSXhhSqz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SUPPORTED_LANGUAGES = {\n",
        "    \"en\": \"English\",\n",
        "    \"es\": \"Spanish\",\n",
        "    \"fr\": \"French\",\n",
        "    \"hi\": \"Hindi\",\n",
        "    \"zh-cn\": \"Chinese (Simplified)\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "Bi24pDJThWJC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CULTURAL_TEMPLATES = {\n",
        "    \"en\": {\n",
        "        \"greeting\": \"Hi! How can I help you today?\",\n",
        "        \"closing\": \"Thanks for reaching out — is there anything else?\",\n",
        "        \"tone\": \"friendly, concise\"\n",
        "    },\n",
        "    \"es\": {\n",
        "        \"greeting\": \"¡Hola! ¿En qué puedo ayudarte hoy?\",\n",
        "        \"closing\": \"Gracias por contactarnos — ¿algo más en lo que pueda ayudar?\",\n",
        "        \"tone\": \"cálido y respetuoso\"\n",
        "    },\n",
        "    \"fr\": {\n",
        "        \"greeting\": \"Bonjour ! Comment puis-je vous aider aujourd'hui ?\",\n",
        "        \"closing\": \"Merci de nous avoir contactés — puis-je faire autre chose pour vous ?\",\n",
        "        \"tone\": \"poli et professionnel\"\n",
        "    },\n",
        "    \"hi\": {\n",
        "        \"greeting\": \"नमस्ते! मैं आपकी कैसे मदद कर सकता/सकती हूँ?\",\n",
        "        \"closing\": \"संपर्क करने के लिए धन्यवाद — क्या और कुछ चाहिए?\",\n",
        "        \"tone\": \"सम्मानजनक और मिलनसार\"\n",
        "    },\n",
        "    \"zh-cn\": {\n",
        "        \"greeting\": \"您好！ 我能为您做些什么？\",\n",
        "        \"closing\": \"感谢您的联系——还有其他需要帮助的吗？\",\n",
        "        \"tone\": \"礼貌和简洁\"\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "rmID86wyhb0P"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_language(text: str) -> Tuple[str, float]:\n",
        "    \"\"\"Detect language and return (lang_code, confidence). Uses langdetect.\"\"\"\n",
        "    try:\n",
        "        langs = detect_langs(text)\n",
        "        if not langs:\n",
        "            return \"en\", 0.0\n",
        "        top = langs[0]\n",
        "        code = top.lang\n",
        "        # Normalize some codes\n",
        "        if code == \"zh-cn\" or code.startswith(\"zh\"):\n",
        "            code = \"zh-cn\"\n",
        "        if code not in SUPPORTED_LANGUAGES:\n",
        "            # fallback mapping for common codes\n",
        "            mapping = {\"zh\": \"zh-cn\", \"hi\": \"hi\", \"en\": \"en\", \"es\": \"es\", \"fr\": \"fr\"}\n",
        "            code = mapping.get(code, \"en\")\n",
        "        return code, float(top.prob)\n",
        "    except Exception:\n",
        "        return \"en\", 0.0"
      ],
      "metadata": {
        "id": "Z6wDXYlXhlLT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cultural_template(lang: str) -> Dict[str, str]:\n",
        "    return CULTURAL_TEMPLATES.get(lang, CULTURAL_TEMPLATES[\"en\"])"
      ],
      "metadata": {
        "id": "hLlVUUs1hpmP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INTENT_KEYWORDS = {\n",
        "    \"greeting\": [\"hello\", \"hi\", \"hey\", \"namaste\", \"hola\", \"bonjour\"],\n",
        "    \"complaint\": [\"problem\", \"complaint\", \"not working\", \"broken\", \"refund\", \"issue\", \"delay\"],\n",
        "    \"order_status\": [\"order\", \"tracking\", \"status\", \"delivery\", \"delivered\", \"shipped\"],\n",
        "    \"product_info\": [\"price\", \"spec\", \"details\", \"feature\", \"size\", \"color\"]\n",
        "}"
      ],
      "metadata": {
        "id": "99n5sd0ChtE2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_intent(text: str) -> Tuple[str, float]:\n",
        "    \"\"\"Very simple intent detection by keyword matching. Returns (intent, score).\"\"\"\n",
        "    text_l = text.lower()\n",
        "    scores = {}\n",
        "    for intent, kws in INTENT_KEYWORDS.items():\n",
        "        s = sum(1 for kw in kws if kw in text_l)\n",
        "        scores[intent] = s\n",
        "    # Pick best\n",
        "    best_intent = max(scores, key=lambda k: scores[k])\n",
        "    score = float(scores[best_intent]) / (len(INTENT_KEYWORDS[best_intent]) + 0.0001)\n",
        "    if score == 0:\n",
        "        return \"unknown\", 0.0\n",
        "    return best_intent, score"
      ],
      "metadata": {
        "id": "Ewvckk1ChxPO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def named_entities(text: str, lang: str=\"en\") -> List[Tuple[str, str]]:\n",
        "    \"\"\"Return list of (entity_text, label). Only if spaCy models are installed.\"\"\"\n",
        "    if not HAS_SPACY:\n",
        "        return []\n",
        "\n",
        "    model_map = {\n",
        "        \"en\": \"en_core_web_sm\",\n",
        "        \"fr\": \"fr_core_news_sm\",\n",
        "        \"es\": \"es_core_news_sm\",\n",
        "        \"hi\": None,\n",
        "        \"zh-cn\": \"zh_core_web_sm\"\n",
        "    }\n",
        "    model_name = model_map.get(lang)\n",
        "    if model_name is None:\n",
        "        return []\n",
        "    try:\n",
        "        nlp = spacy.load(model_name)\n",
        "    except Exception:\n",
        "        try:\n",
        "            # Attempt to download might be needed; skip if not present\n",
        "            return []\n",
        "        except Exception:\n",
        "            return []\n",
        "    doc = nlp(text)\n",
        "    return [(ent.text, ent.label_) for ent in doc.ents]"
      ],
      "metadata": {
        "id": "lY4fbh-Uh79U"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "_embedding_model = None\n",
        "_kb_embeddings = None\n",
        "_kb_texts = None"
      ],
      "metadata": {
        "id": "LamfRX1aiGQv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_embeddings(kb_texts: List[str]):\n",
        "    global _embedding_model, _kb_embeddings, _kb_texts\n",
        "    if not HAS_SENTENCE_TRANSFORMERS:\n",
        "        return\n",
        "    if _embedding_model is None:\n",
        "        _embedding_model = SentenceTransformer(EMBEDDING_MODEL)\n",
        "    _kb_texts = kb_texts\n",
        "    _kb_embeddings = _embedding_model.encode(kb_texts, convert_to_tensor=True)"
      ],
      "metadata": {
        "id": "putl4mO_iYfe"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieval_candidates(query: str, top_k: int = 3) -> List[Tuple[str, float]]:\n",
        "    \"\"\"Return top-k KB sentences + score. KB must be initialized with init_embeddings.\"\"\"\n",
        "    if not HAS_SENTENCE_TRANSFORMERS or _kb_embeddings is None:\n",
        "        return []\n",
        "    q_emb = _embedding_model.encode(query, convert_to_tensor=True)\n",
        "    hits = util.semantic_search(q_emb, _kb_embeddings, top_k=top_k)[0]\n",
        "    results = []\n",
        "    for h in hits:\n",
        "        idx = h['corpus_id']\n",
        "        score = float(h['score'])\n",
        "        results.append((_kb_texts[idx], score))\n",
        "    return results"
      ],
      "metadata": {
        "id": "UNwvvQi-ieaR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HF_TRANSLATOR = None\n",
        "\n",
        "def init_hf_models():\n",
        "    \"\"\"Initialize minimal HuggingFace models if available. Lazy load to reduce startup cost.\"\"\"\n",
        "    global HF_TRANSLATOR, HAS_TRANSFORMERS\n",
        "    if not HAS_TRANSFORMERS:\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "        HF_TRANSLATOR = {\"model\": model, \"tokenizer\": tokenizer, \"name\": model_name}\n",
        "    except Exception:\n",
        "        HF_TRANSLATOR = None"
      ],
      "metadata": {
        "id": "xvM6xgWRiluk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hf_translate(text: str, source_lang: str, target_lang: str) -> str:\n",
        "    \"\"\"Use mBART many-to-many to translate text (fallback).\"\"\"\n",
        "    if HF_TRANSLATOR is None:\n",
        "        return text\n",
        "    tok = HF_TRANSLATOR[\"tokenizer\"]\n",
        "    model = HF_TRANSLATOR[\"model\"]\n",
        "\n",
        "    code_map = {\"en\": \"en_XX\", \"fr\": \"fr_XX\", \"es\": \"es_XX\", \"hi\": \"hi_IN\", \"zh-cn\":\"zh_CN\"}\n",
        "    tgt = code_map.get(target_lang, \"en_XX\")\n",
        "    try:\n",
        "        tok.src_lang = code_map.get(source_lang, \"en_XX\")\n",
        "        encoded = tok(text, return_tensors=\"pt\")\n",
        "        generated = model.generate(**encoded, forced_bos_token_id=tok.lang_code_to_id[tgt], max_length=512)\n",
        "        out = tok.batch_decode(generated, skip_special_tokens=True)[0]\n",
        "        return out\n",
        "    except Exception:\n",
        "        return text"
      ],
      "metadata": {
        "id": "Tkph_JXnixm2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response_openai(system_prompt: str, user_message: str, lang: str, temperature: float=0.2) -> str:\n",
        "    \"\"\"Generate a reply using OpenAI chat completion (if key is available).\"\"\"\n",
        "    if not HAS_OPENAI or \"OPENAI_API_KEY\" not in os.environ:\n",
        "        return \"\"\n",
        "    openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "    template = get_cultural_template(lang)\n",
        "    system = f\"{system_prompt}\\nTone: {template.get('tone','friendly')}\\nLanguage: {SUPPORTED_LANGUAGES.get(lang,'English')}\"\n",
        "    try:\n",
        "        resp = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\":\"system\", \"content\": system},\n",
        "                {\"role\":\"user\", \"content\": user_message}\n",
        "            ],\n",
        "            temperature=temperature,\n",
        "            max_tokens=400\n",
        "        )\n",
        "        return resp.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        try:\n",
        "            resp = openai.Completion.create(\n",
        "                model=\"text-davinci-003\",\n",
        "                prompt=f\"{system}\\n\\nUser: {user_message}\\nAssistant:\",\n",
        "                temperature=temperature,\n",
        "                max_tokens=400\n",
        "            )\n",
        "            return resp.choices[0].text.strip()\n",
        "        except Exception:\n",
        "            return f\"(OpenAI call failed: {e})\""
      ],
      "metadata": {
        "id": "qsLqmUU_kon_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response_hf(prompt: str, lang: str, max_length=200) -> str:\n",
        "    \"\"\"Fallback: Use HF mBART to 'generate' a reply by translating to English, generating simple template reply, then translating back.\n",
        "       This is a basic approach to avoid loading a separate generator model.\"\"\"\n",
        "    tpl = get_cultural_template(lang)\n",
        "    reply = f\"{tpl['greeting']} I understand you'd like help. {tpl['closing']}\"\n",
        "    return reply"
      ],
      "metadata": {
        "id": "3oChVJlok1BV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st.set_page_config(page_title=\"Multilingual Customer Service Chatbot\", layout=\"wide\")\n",
        "st.title(\"Multilingual Customer Service Chatbot\")\n",
        "\n",
        "with st.sidebar:\n",
        "    st.header(\"Settings\")\n",
        "    openai_key = st.text_input(\"OpenAI API Key (optional)\", type=\"password\", help=\"If provided, OpenAI will be used for generation/translation.\")\n",
        "    if openai_key:\n",
        "        os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
        "    use_hf = st.checkbox(\"Prefer local HuggingFace models if available\", value=False)\n",
        "    if use_hf and not HAS_TRANSFORMERS:\n",
        "        st.warning(\"Transformers not installed; local models unavailable.\")\n",
        "    st.markdown(\"**Supported languages:** \" + \", \".join([f\"{k} ({v})\" for k,v in SUPPORTED_LANGUAGES.items()]))\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"Advanced options\")\n",
        "    temperature = st.slider(\"Response creativity (temperature)\", 0.0, 1.0, 0.2)\n",
        "    show_ner = st.checkbox(\"Show Named Entities (spaCy)\", value=False)\n",
        "    show_retrieval = st.checkbox(\"Use KB retrieval fallback\", value=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZ4ddiQnk8aE",
        "outputId": "3c31e699-c411-4d8f-984f-a2a4d4e73f6e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-11-05 10:33:15.717 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.721 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.909 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-11-05 10:33:15.910 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.910 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.912 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.913 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.914 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.915 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.915 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.917 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.918 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.918 Session state does not function when running a script without `streamlit run`\n",
            "2025-11-05 10:33:15.919 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.920 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.921 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.922 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.923 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.923 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.925 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.926 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.927 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.928 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.928 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.929 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.930 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.931 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.933 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.934 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.934 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.935 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.936 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.937 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.937 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.939 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.940 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.940 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.942 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.942 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.943 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.944 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.945 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.946 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.947 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.947 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.948 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.949 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.950 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:33:15.950 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "KB_SNIPPETS = [\n",
        "    \"You can track your order by visiting the Orders page and entering your tracking number.\",\n",
        "    \"We accept returns within 30 days of delivery. Items must be unused and in original packaging.\",\n",
        "    \"Standard shipping takes 3-5 business days; express shipping takes 1-2 business days.\",\n",
        "    \"For refunds, it can take 5-10 business days after we receive the returned item to process.\"\n",
        "]\n",
        "if show_retrieval and HAS_SENTENCE_TRANSFORMERS:\n",
        "    init_embeddings(KB_SNIPPETS)\n"
      ],
      "metadata": {
        "id": "W-15KTB5k8HV"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if show_retrieval and HAS_SENTENCE_TRANSFORMERS:\n",
        "    init_embeddings(KB_SNIPPETS)\n",
        "\n",
        "# Conversation state (Streamlit session_state)\n",
        "if \"history\" not in st.session_state:\n",
        "    st.session_state.history = []\n",
        "\n",
        "st.subheader(\"Chat\")\n",
        "\n",
        "col1, col2 = st.columns([3,1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6cLxNUYlNiF",
        "outputId": "70424828-b13f-4058-bbb6-4a4976bf9a31"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-11-05 10:34:16.516 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:34:16.518 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:34:16.519 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:34:16.520 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:34:16.521 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:34:16.521 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:34:16.523 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:34:16.523 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:34:16.524 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with col1:\n",
        "    user_input = st.text_area(\"Your message\", height=120, placeholder=\"Type your message here...\")\n",
        "    if st.button(\"Send\"):\n",
        "        if not user_input.strip():\n",
        "            st.warning(\"Please type a message.\")\n",
        "        else:\n",
        "            lang, conf = detect_language(user_input)\n",
        "            st.session_state.history.append({\"role\":\"user\", \"text\": user_input, \"lang\": lang, \"lang_conf\": conf})\n",
        "\n",
        "            intent, intent_score = detect_intent(user_input)\n",
        "            ents = named_entities(user_input, lang) if show_ner else []\n",
        "\n",
        "            retrieval_results = []\n",
        "            if show_retrieval and HAS_SENTENCE_TRANSFORMERS:\n",
        "                retrieval_results = retrieval_candidates(user_input, top_k=2)\n",
        "\n",
        "            system_prompt = \"You are a helpful multilingual customer service assistant for Acme Corp. Provide short, polite answers and ask clarifying questions only when needed.\"\n",
        "\n",
        "            if retrieval_results and retrieval_results[0][1] > 0.4:\n",
        "                system_prompt += \"\\nRelevant information:\\n\" + \"\\n\".join([f\"- {r[0]}\" for r in retrieval_results])\n",
        "\n",
        "            reply = \"\"\n",
        "            used_provider = \"none\"\n",
        "            if openai_key and HAS_OPENAI and not use_hf:\n",
        "                used_provider = \"OpenAI\"\n",
        "                reply = generate_response_openai(system_prompt, user_input, lang, temperature=temperature)\n",
        "            else:\n",
        "\n",
        "                used_provider = \"HuggingFace (fallback)\" if HAS_TRANSFORMERS else \"template\"\n",
        "                if HAS_TRANSFORMERS:\n",
        "                    if HF_TRANSLATOR is None:\n",
        "                        try:\n",
        "                            init_hf_models()\n",
        "                        except Exception:\n",
        "                            pass\n",
        "\n",
        "                    reply = generate_response_hf(user_input, lang, max_length=200)\n",
        "                else:\n",
        "                    reply = generate_response_hf(user_input, lang)\n",
        "\n",
        "            st.session_state.history.append({\"role\":\"assistant\", \"text\": reply, \"lang\": lang, \"provider\": used_provider})\n",
        "\n",
        "            st.success(f\"Detected language: {SUPPORTED_LANGUAGES.get(lang,'English')} (confidence {conf:.2f}) — intent: {intent} ({intent_score:.2f}) — provider: {used_provider}\")\n",
        "            if ents:\n",
        "                st.info(\"Named Entities detected: \" + \", \".join([f\"{t}({l})\" for t,l in ents]))\n",
        "            if retrieval_results:\n",
        "                st.info(\"Retrieval matches: \" + \"; \".join([f\"{r[0][:80]}... ({r[1]:.2f})\" for r in retrieval_results]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZKTuSCPlXh_",
        "outputId": "971501e7-ed21-44f8-f36f-8f40670ad74c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-11-05 10:36:07.067 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:36:07.068 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:36:07.071 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:36:07.071 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:36:07.072 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:36:07.072 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:36:07.073 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:36:07.074 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:36:07.074 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:36:07.075 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:36:07.076 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:36:07.076 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:36:07.077 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with col2:\n",
        "    st.markdown(\"**Conversation**\")\n",
        "    for msg in reversed(st.session_state.history[-10:]):\n",
        "        if msg['role'] == 'assistant':\n",
        "            st.markdown(f\"**Assistant ({msg.get('lang','en')}) — {msg.get('provider','')}**\\n> {msg['text']}\")\n",
        "        else:\n",
        "            st.markdown(f\"**User ({msg.get('lang','en')})**\\n> {msg['text']}\")\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"### Developer notes & extension ideas\")\n",
        "st.markdown(\"\"\"\n",
        "- To improve intent detection replace the rule-based NLU with a small classifier (fine-tune a multilingual model).\n",
        "- For production, prefer OpenAI or a hosted LLM for generation; HF mT5/mBART variants can be used but are large.\n",
        "- Add culturally aware templates per-country (e.g., formal vs informal pronouns in Spanish, honorifics in Japanese/Korean).\n",
        "- Add logging & analytics to measure language distribution, fallback rates, and user satisfaction per language.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7V8ceLNluHt",
        "outputId": "90ecb2a1-7e87-4db7-e0f3-a8cdc955af19"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-11-05 10:36:30.715 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:36:30.716 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:36:30.717 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:36:30.719 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:36:30.719 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:36:30.720 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:36:30.720 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:36:30.722 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:36:30.722 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:36:30.723 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:36:30.723 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:36:30.724 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-05 10:36:30.725 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}